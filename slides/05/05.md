![:wip](Under construction)

class: title
## NPFL114, Lecture 05

# Convolutional Networks II

![:pdf 26%,,padding-right:64px](../res/mff.pdf)
![:image 33%,,padding-left:64px](../res/ufal.svg)

.author[
Milan Straka
]

---
# Convolution Layer

The $K$ is usually called a _kernel_ or a _filter_, and we generally apply
several of them at the same time.

Consider an input image with $C$ channels. The convolution layer with
$F$ filters of width $W$, height $H$ and stride $S$ produces an output with $F$ channels
kernels of total size $W Ã— H Ã— C Ã— F$ and is computed as
$$(â‡‰I \* â‡‰K)\_{i, j, k} = âˆ‘\_{m, n, o} â‡‰I\_{i\cdot S + m, j\cdot S + n, o} â‡‰K\_{m, n, o, k}.$$

--

There are multiple padding schemes, most common are:
- `valid`: we only use valid pixels, which causes the result to me smaller
- `same`: we pad original image with zero pixels so that the result is exactly
  the size of the input

---
# Convolution Layer

There are two prevalent image formats:
- `NHWC` or `channels_last`: The dimensions of the 4-dimensional image tensor
  are batch, height, width, and channels.

  The original TensorFlow format, faster on CPU.

--

- `NCHW` or `channels_first`: The dimensions of the 4-dimensional image tensor
  are batch, channel, height, and width.

  Usual GPU format (used by CUDA and nearly all frameworks); on TensorFlow, not
  all CPU kernels are available with this layout.

---
# Pooling

Pooling is an operation similar to convolution, but we perform a fixed operation
instead of multiplying by a kernel.

- Max pooling: minor translation invariance
- Average pooling

![:pdf 80%,center](pooling.pdf)

---
class: center
# VGG â€“ 2014 (6.8% error)

![:pdf 62%](vgg_architecture.pdf)
![:pdf 45%](vgg_parameters.pdf)

---
class: middle
# Inception (GoogLeNet) â€“ 2014 (6.7% error)

![:pdf 100%](inception_block.pdf)

---
class: middle
# Inception (GoogLeNet) â€“ 2014 (6.7% error)

![:pdf 100%](inception_block_reduction.pdf)

---
class: middle
# Inception (GoogLeNet) â€“ 2014 (6.7% error)

![:pdf 100%](inception_architecture.pdf)

---
class: center
# Inception (GoogLeNet) â€“ 2014 (6.7% error)

![:pdf 16%,,vertical-align:middle](inception_graph.pdf)
aux. classifiers, 0.3 weight

---
# Batch Normalization

_Internal covariate shift_ refers to the change in the distributions
of hidden node activations due to the updates of network parameters
during training.

Let $â†’x = (x\_1, \ldots, x\_d)$ be $d$-dimensional input. We would like to
normalize each dimension as $$\hat x\_i = \frac{x\_i - ğ”¼[x\_i]}{\sqrt{\Var[x\_i]}}.$$
Furthermore, it may be advantageous to learn suitable scale $Î³\_i$ and shift $Î²\_i$ to
produce normalized value $$y\_i = Î³\_i\hat x\_i + Î²\_i.$$

---
# Batch Normalization

Consider a mini-batch of $m$ examples $(â†’x^{(1)}, \ldots, â†’x^{(m)})$.

_Batch normalizing transform_ of the mini-batch is the following transformation.

.algorithm[
**Inputs**: Mini-batch $(â†’x^{(1)}, \ldots, â†’x^{(m)})$, $Îµ âˆˆ â„$<br>
**Outputs**: Normalized batch $(â†’y^{(1)}, \ldots, â†’y^{(m)})$
- $â†’Î¼ â† \frac{1}{m} âˆ‘\_{i = 1}^m â†’x^{(i)}$
- $â†’Ïƒ^2 â† \frac{1}{m} âˆ‘\_{i = 1}^m (â†’x^{(i)} - Î¼)^2$
- $\hatâ†’x^{(i)} â† (â†’x^{(i)} - â†’Î¼) / \sqrt{Ïƒ^2 + Îµ}$
- $â†’y^{(i)} â† â†’Î³ \hatâ†’x^{(i)} + â†’Î²$
]

--

Batch normalization is commonly added just before a nonlinearity. Therefore, we
replace $f(â‡‰Wâ†’x + â†’b)$ by $f(\textit{BN}(â‡‰Wâ†’x))$.

--

During inference, $â†’Î¼$ and $â†’Ïƒ^2$ are fixed. They are either precomputed
after training on the whole training data, or an exponential moving average is
updated during training.

---
class: middle
# Inception with BatchNorm (4.8% error)

![:pdf 100%](inception_batchnorm.pdf)

---
class: middle, center
# Inception v2 and v3 â€“ 2015 (3.6% error)

![:image 55%](inception3_conv5.png)
![:image 35%](inception3_conv3.png)

---
class: middle
# Inception v2 and v3 â€“ 2015 (3.6% error)

![:pdf 32%](inception3_inception_a.pdf)
![:pdf 32%](inception3_inception_b.pdf)
![:pdf 32%](inception3_inception_c.pdf)

---
class: middle, center
# Inception v2 and v3 â€“ 2015 (3.6% error)

![:pdf 70%](inception3_architecture.pdf)

---
class: middle, center
# Inception v2 and v3 â€“ 2015 (3.6% error)

![:pdf 70%](inception3_ablation.pdf)

---
class: middle
# ResNet â€“ 2015 (3.6% error)

![:pdf 100%](resnet_depth_effect.pdf)

---
class: middle
# ResNet â€“ 2015 (3.6% error)

![:pdf 100%](resnet_block.pdf)

---
class: middle
# ResNet â€“ 2015 (3.6% error)

![:pdf 100%](resnet_block_reduced.pdf)

---
class: middle
# ResNet â€“ 2015 (3.6% error)

![:pdf 100%](resnet_architecture.pdf)

---
class: middle
# ResNet â€“ 2015 (3.6% error)

![:pdf 100%](resnet_residuals.pdf)

---
class: middle, full
# ResNet â€“ 2015 (3.6% error)

![:image 100%](../02/nn_loss.jpg)
