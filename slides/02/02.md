class: title
## NPFL114, Lecture 02

# Training Neural Networks

![:pdf 26%,,padding-right:64px](../res/mff.pdf)
![:image 33%,,padding-left:64px](../res/ufal.svg)

.author[
Milan Straka
]

---
# Machine Learning Basics

We usually have a **training set**, which is assumed to consist of examples
generated independently from a **data generating distribution**.

The goal of optimization is to match the training set as well as possible.

--

However, the main goal of machine learning is to perform well on _previously
unseen_ data, so called **generalization error** or **test error**. We typically
estimate the generalization error using a **test set** of examples independent
of the training set.

---
# Machine Learning Basics

Challenges in machine learning:
- _underfitting_

- _overfitting_

--

![:pdf 100%](underfitting_overfitting.pdf)

---
# Machine Learning Basics

We control whether a model underfits or overfits by modifying its _capacity_.
(representational capacity, effective capacity).

--

![:pdf 90%,center](generalization_error.pdf)

--

The **No free lunch theorem** (Wolpert, 1996) states that averaging over
all possible data distributions, every classification algorithm achieves
same error when processing previously unseen examples. In a sense, no machine
learning algorithm is universally better than any other.

---
# Machine Learning Basics

Any change in the machine learning algorithm that is designed to reduce
generalization error but not necessarily its training error is called
**regularization**.

--

$L\_2$ regularization (also called weighted decay) penalizes models
with large weights (i.e., penalty of $||â†’Î¸||^2$).

![:pdf 90%,center](regularization.pdf)

---
# Machine Learning Basics

_Hyperparameters_ are not adapted by learning algorithm itself.

Usually a **validation set** or **development set** is used to
estimate generalization error, allowing to update hyperparameters accordingly.

---
# Loss Function

A model is usually trained in order to minimize a _loss_ on the training data.

--

Assuming that a model computes $f(â†’x;â†’Î¸)$ using parameters $â†’Î¸$,
_mean square error_ is computed as $$âˆ‘\_i \left(f(â†’x^{(i)}; â†’Î¸) - y^{(i)}\right)^2.$$

--

A common principle used to design loss functions is _maximum likelihood
principle_.

---
# Maximum Likelihood Estimation

Let $\mathbb X = \\{â†’x^{(1)}, â†’x^{(2)}, \ldots, â†’x^{(m)}\\}$ be training data drawn
independently from data generating distribution $p\_\textrm{data}$. We denote
the empirical data distribution as $\hat p\_\textrm{data}$.

Let $p\_\textrm{model}(â†’x; â†’Î¸)$ be a family of distributions. The
*maximum likelihood estimation* of parameters $â†’Î¸$ is:

$$\begin{aligned}
â†’Î¸\_\mathrm{ML} &= \argmax\_â†’Î¸ p\_\textrm{model}(\mathbb X; â†’Î¸) \\\
                &= \argmax\_â†’Î¸ âˆ\nolimits\_{i=1}^m p\_\textrm{model}(â†’x^{(i)}; â†’Î¸) \\\
                &= \argmin\_â†’Î¸ âˆ‘\nolimits\_{i=1}^m -\log p\_\textrm{model}(â†’x^{(i)}; â†’Î¸) \\\
                &= \argmin\_â†’Î¸ \mathbb E\_{â‡â†’x âˆ¼ \hat p\_\textrm{data}} [-\log p\_\textrm{model}(â†’x; â†’Î¸)] \\\
                &= \argmin\_â†’Î¸ H(\hat p\_\textrm{data}, p\_\textrm{model}(â†’x; â†’Î¸)) \\\
                &= \argmin\_â†’Î¸ D\_\textrm{KL}(\hat p\_\textrm{data}||p\_\textrm{model}(â†’x; â†’Î¸)) \color{gray} + H(\hat p\_\textrm{data})
\end{aligned}$$

---
# Maximum Likelihood Estimation

Easily generalized to situations where our goal is predict $y$ given $â†’x$.
$$\begin{aligned}
â†’Î¸\_\mathrm{ML} &= \argmax\_â†’Î¸ p\_\textrm{model}(\mathbb Y | \mathbb X; â†’Î¸) \\\
                &= \argmax\_â†’Î¸ âˆ\nolimits\_{i=1}^m p\_\textrm{model}(y^{(i)} | â†’x^{(i)}; â†’Î¸) \\\
                &= \argmin\_â†’Î¸ âˆ‘\nolimits\_{i=1}^m -\log p\_\textrm{model}(y^{(i)} | â†’x^{(i)}; â†’Î¸) \\\
\end{aligned}$$

The resulting _loss function_ called _negative log likelihood_, or
_cross-entropy_ or _Kullback-Leibler divegence_.

---
# Mean Square Error as MLE

Assume our goal is to perform a regression, i.e., to predict $p(y | â†’x)$ for $y âˆˆ â„$.

Let $\hat y(â†’x; â†’Î¸)$ give the prediction of mean of $y$.

We define $p(y | â†’x)$ as $\N(y; \hat y(â†’x; â†’Î¸), Ïƒ^2)$ for a given fixed $Ïƒ$.
Then:
$$\begin{aligned}
\argmax\_â†’Î¸ p(y | â†’x; â†’Î¸) =& \argmin\_â†’Î¸ âˆ‘\_{i=1}^m -\log p(y^{(i)} | â†’x^{(i)} ; â†’Î¸) \\\
                          =& \argmin\_â†’Î¸ âˆ‘\_{i=1}^m -\log \sqrt{\frac{1}{2Ï€Ïƒ^2}}
                            e ^ {\normalsize -\frac{(y^{(i)} - \hat y(â†’x^{(i)}; â†’Î¸))^2}{2Ïƒ^2}} \\\
                          =& -m \log Ïƒ - \frac{m}{2} \log 2Ï€ \\\
                           & - \argmin\_â†’Î¸ âˆ‘\_{i=1}^m -\frac{(y^{(i)} - \hat y(â†’x^{(i)}; â†’Î¸))^2}{2Ïƒ^2} \\\
                          =& \argmin\_â†’Î¸ âˆ‘\_{i=1}^m -\frac{||y^{(i)} - \hat y(â†’x^{(i)}; â†’Î¸)||^2}{2Ïƒ^2}
\end{aligned}$$

---
# Gradient Descent

Let a model compute $f(â†’x;â†’Î¸)$ using parameters $â†’Î¸$. In order to compute $J(â†’Î¸)
= \argmin\_â†’Î¸ ğ”¼\_{(â†’x, y)âˆ¼\hat p\_\textrm{data}} L(f(â†’x; â†’Î¸), y)$, we may use _gradient descent_:
$$â†’Î¸ â† â†’Î¸ - Î±âˆ‡\_â†’Î¸J(â†’Î¸)$$


## Gradient Descent

We use all training data to compute the $J(â†’Î¸)$.

## Online (or Stochastic) Gradient Descent

We estimate the expectation in $J(â†’Î¸)$ using a single randomly sampled example
from the training data. Such estimate is unbiased, but very noisy.

## Minibatch SGD

The minibatch SGD is a trade-off between gradient descent and SGD â€“ the
expectation in $J(â†’Î¸)$ is estimated using $m$ random independent examples from
the training data.

---
# Gradient Descent

![:pdf 100%](gradient_descent.pdf)

---
class: middle, center, full
# Gradient Descent

![:image 100%](nn_loss.jpg)

---
# Backpropagation

Assume we want to compute partial derivatives of a given loss function $J$ and
let $\frac{âˆ‚J}{âˆ‚z}$ be known.

![:pdf 45%,center](chain_rule.pdf)

$$\begin{gathered}
\frac{âˆ‚J}{âˆ‚y\_i} = \frac{âˆ‚J}{âˆ‚z} \frac{âˆ‚z}{âˆ‚y\_i} = \frac{âˆ‚J}{âˆ‚z} \frac{âˆ‚g(â†’y)}{âˆ‚y\_i} \\\
\frac{âˆ‚J}{âˆ‚â†’x\_i} = \frac{âˆ‚J}{âˆ‚z} \frac{âˆ‚z}{âˆ‚y\_i} \frac{âˆ‚y\_i}{âˆ‚â†’x\_i} = \frac{âˆ‚J}{âˆ‚z} \frac{âˆ‚g(â†’y)}{âˆ‚y\_i} \frac{âˆ‚f(â†’x\_i)}{âˆ‚â†’x\_i}
\end{gathered}$$

---
class: middle, center
# Backpropagation Example

![:pdf 80%](net.pdf)

---
class: middle, center
# Backpropagation Example

![:pdf 80%](net-forward.pdf)

---
class: middle, center, full
# Backpropagation Example

![:pdf 98%](net-backward.pdf)

This is meant to be frightening â€“ you do **not** do this manually when training.

---
class: middle
# Backpropagation Algorithm

#### Forward Propagation
.algorithm[
**Inputs**: Network with nodes $u^{(1)}, u^{(2)}, \ldots, u^{(n)}$ numbered in
topological order, each node being computed as $u^{(i)} = f^{(i)}(\mathbb A^{(i)})$
for $\mathbb A^{(i)}$ composed of values of the predecessors $P(u^{(i)})$ of
$u^{(i)}$. <br>
**Outputs**: Value of $u^{(n)}$.
- For $i = 1, \ldots, n$:
    - $\mathbb A^{(i)} â† \lbrace u^{(j)} | j âˆˆ P(u^{(i)})\rbrace$
    - $u^{(i)} â† f^{(i)}(\mathbb A^{(i)})$
- Return $u^{(n)}$
]

---
class: middle
# Backpropagation Algorithm

#### Simple Variant of Backpropagation
.algorithm[
**Inputs**: The network as in the Forward propagation algorithm.<br>
**Outputs**: Partial derivatives $g^{(i)} = \frac{âˆ‚u^{(n)}}{âˆ‚u^{(i)}}$ of $u^{(n)}$ with respect to all $u^{(i)}$.
- Run forward propagation to compute all $u^{(i)}$
- $g^{(n)} = 1$
- For $i = n-1, \ldots, 1$:
    - $g^{(i)} â† âˆ‘\_{j:iâˆˆP(u^{(j)})} g^{(j)} \frac{âˆ‚u^{(j)}}{âˆ‚u^{(i)}}$
- Return $â†’g$
]

In practice, we do not usually represent network as a collection of scalar
nodes; instead we represent it as a collection of tensor functions â€“ most
usually functions $f: â„^n â†’ â„^m$. Then $\frac{âˆ‚f(â†’x)}{âˆ‚â†’x}$ is a Jacobian.
However, the backpropagation algorithm is analogous.

---
class: center, middle
# Neural Network Architecture Ã  la '80s

![:dot 65%](digraph G { rankdir=LR; splines=line;
  x3 [ label=<x<sub><font point-size="10">3</font></sub>>]
  x4 [ label=<x<sub><font point-size="10">4</font></sub>>]
  x1 [ label=<x<sub><font point-size="10">1</font></sub>>]
  x2 [ label=<x<sub><font point-size="10">2</font></sub>>]
  h3 [ label=<h<sub><font point-size="10">3</font></sub>>]
  h4 [ label=<h<sub><font point-size="10">4</font></sub>>]
  h1 [ label=<h<sub><font point-size="10">1</font></sub>>]
  h2 [ label=<h<sub><font point-size="10">2</font></sub>>]
  y1 [ label=<y<sub><font point-size="10">1</font></sub>>]
  y2 [ label=<y<sub><font point-size="10">2</font></sub>>]
  {x1, x2, x3, x4} -> {h1, h2, h3, h4} -> {y1, y2}
  lx [ label=<Input<br/>layer>; shape=none ]
  la [ label=<Hidden<br/>layer>; shape=none ]
  ly [ label=<Output<br/>layer>; shape=none ]
  lx -> la -> ly [ style=invis ]
})

---
# Neural Network Activation Functions

## Hidden Layers Derivatives
- $Ïƒ$: $$\frac{dÏƒ(x)}{dx} = Ïƒ(x) \cdot (1-Ïƒ(x))$$
- $\tanh$: $$\frac{d\tanh(x)}{dx} = 1 - \tanh(x)^2$$
- ReLU:
  $$ \frac{d\ReLU(x)}{dx} = \begin{cases} 1 &\text{if } x > 0 \\\ \textrm{NaN} &\text{if }x = 0 \\\ 0 &\text{if } x < 0 \end{cases}$$

---
class: middle
# Stochastic Gradient Descent

#### Stochastic Gradient Descent (SGD) Algorithm
.algorithm[
**Inputs**: NN computing function $f(â†’x; â†’Î¸)$ with initial value of parameters $â†’Î¸$.<br>
**Inputs**: Learning rate $Î±$.<br>
**Outputs**: Updated parameters $â†’Î¸$.
- Repeat until stopping criterion is met:
    - Sample a minibatch of $m$ training examples $(â†’x^{(i)}, y^{(i)})$
    - $â†’g â† \frac{1}{m} âˆ‡\_{â†’Î¸} âˆ‘\_i L(f(â†’x^{(i)}; â†’Î¸), y^{(i)})$
    - $â†’Î¸ â† â†’Î¸ - Î±â†’g$
]

---
# SGD With Momentum

#### SGD With Momentum
.algorithm[
**Inputs**: NN computing function $f(â†’x; â†’Î¸)$ with initial value of parameters $â†’Î¸$.<br>
**Inputs**: Learning rate $Î±$, momentum $Î²$.<br>
**Outputs**: Updated parameters $â†’Î¸$.
- Repeat until stopping criterion is met:
    - Sample a minibatch of $m$ training examples $(â†’x^{(i)}, y^{(i)})$
    - $â†’g â† \frac{1}{m} âˆ‡\_{â†’Î¸} âˆ‘\_i L(f(â†’x^{(i)}; â†’Î¸), y^{(i)})$
    - $â†’v â† Î²â†’v - Î±â†’g$
    - $â†’Î¸ â† â†’Î¸ + â†’v$
]
![:pdf 30%,center](momentum.pdf)

---
# SGD With Nesterov Momentum

#### SGD With Nesterov Momentum
.algorithm[
**Inputs**: NN computing function $f(â†’x; â†’Î¸)$ with initial value of parameters $â†’Î¸$.<br>
**Inputs**: Learning rate $Î±$, momentum $Î²$.<br>
**Outputs**: Updated parameters $â†’Î¸$.
- Repeat until stopping criterion is met:
    - Sample a minibatch of $m$ training examples $(â†’x^{(i)}, y^{(i)})$
    - $â†’Î¸ â† â†’Î¸ + Î²â†’v$
    - $â†’g â† \frac{1}{m} âˆ‡\_{â†’Î¸} âˆ‘\_i L(f(â†’x^{(i)}; â†’Î¸), y^{(i)})$
    - $â†’v â† Î²â†’v - Î±â†’g$
    - $â†’Î¸ â† â†’Î¸ - Î±â†’g$
]
![:image 70%,center](nesterov.jpg)

---
class: middle
# Algorithms with Adaptive Learning Rates

#### AdaGrad (2011)
.algorithm[
**Inputs**: NN computing function $f(â†’x; â†’Î¸)$ with initial value of parameters $â†’Î¸$.<br>
**Inputs**: Learning rate $Î±$, constant $Îµ$ (usually $10^{-8}$).<br>
**Outputs**: Updated parameters $â†’Î¸$.
- Repeat until stopping criterion is met:
    - Sample a minibatch of $m$ training examples $(â†’x^{(i)}, y^{(i)})$
    - $â†’g â† \frac{1}{m} âˆ‡\_{â†’Î¸} âˆ‘\_i L(f(â†’x^{(i)}; â†’Î¸), y^{(i)})$
    - $â†’r â† â†’r + â†’g^2$
    - $â†’Î¸ â† â†’Î¸ - \frac{Î±}{\sqrt{â†’r + Îµ}}â†’g$
]

---
class: middle
# Algorithms with Adaptive Learning Rates

#### RMSProp (2012)
.algorithm[
**Inputs**: NN computing function $f(â†’x; â†’Î¸)$ with initial value of parameters $â†’Î¸$.<br>
**Inputs**: Learning rate $Î±$, momentum $Î²$, constant $Îµ$ (usually $10^{-8}$).<br>
**Outputs**: Updated parameters $â†’Î¸$.
- Repeat until stopping criterion is met:
    - Sample a minibatch of $m$ training examples $(â†’x^{(i)}, y^{(i)})$
    - $â†’g â† \frac{1}{m} âˆ‡\_{â†’Î¸} âˆ‘\_i L(f(â†’x^{(i)}; â†’Î¸), y^{(i)})$
    - $â†’r â† Î²â†’r + (1-Î²)â†’g^2$
    - $â†’Î¸ â† â†’Î¸ - \frac{Î±}{\sqrt{â†’r + Îµ}}â†’g$
]

---
# Algorithms with Adaptive Learning Rates

#### Adam (2014)
.algorithm[
**Inputs**: NN computing function $f(â†’x; â†’Î¸)$ with initial value of parameters $â†’Î¸$.<br>
**Inputs**: Learning rate $Î±$ (default 0.001), constant $Îµ$ (usually $10^{-8}$).<br>
**Inputs**: Momentum $Î²\_1$ (default 0.9), momentum $Î²\_2$ (default 0.999).<br>
**Outputs**: Updated parameters $â†’Î¸$.
- $â†’s â† 0$, $â†’r â† 0$, $t â† 0$
- Repeat until stopping criterion is met:
    - Sample a minibatch of $m$ training examples $(â†’x^{(i)}, y^{(i)})$
    - $â†’g â† \frac{1}{m} âˆ‡\_{â†’Î¸} âˆ‘\_i L(f(â†’x^{(i)}; â†’Î¸), y^{(i)})$
    - $t â† t + 1$
    - $â†’s â† Î²\_1â†’s + (1-Î²\_1)â†’g$ &nbsp; &nbsp; _(biased first moment estimate)_
    - $â†’r â† Î²\_2â†’r + (1-Î²\_2)â†’g^2$ &nbsp;_(biased second moment estimate)_
    - $\hatâ†’s â† â†’s / (1 - Î²\_1^t)$
    - $\hatâ†’r â† â†’r / (1 - Î²\_2^t)$
    - $â†’Î¸ â† â†’Î¸ - \frac{Î±}{\sqrt{\hatâ†’r + Îµ}}\hatâ†’s$
]

---
# Algorithms with Adaptive Learning Rates

#### Adam (2014)
.algorithm[
**Inputs**: NN computing function $f(â†’x; â†’Î¸)$ with initial value of parameters $â†’Î¸$.<br>
**Inputs**: Learning rate $Î±$ (default 0.001), constant $Îµ$ (usually $10^{-8}$).<br>
**Inputs**: Momentum $Î²\_1$ (default 0.9), momentum $Î²\_2$ (default 0.999).<br>
**Outputs**: Updated parameters $â†’Î¸$.
- $â†’s â† 0$, $â†’r â† 0$, $t â† 0$
- Repeat until stopping criterion is met:
    - Sample a minibatch of $m$ training examples $(â†’x^{(i)}, y^{(i)})$
    - $â†’g â† \frac{1}{m} âˆ‡\_{â†’Î¸} âˆ‘\_i L(f(â†’x^{(i)}; â†’Î¸), y^{(i)})$
    - $t â† t + 1$
    - $â†’s â† Î²\_1â†’s + (1-Î²\_1)â†’g$ &nbsp; &nbsp; _(biased first moment estimate)_
    - $â†’r â† Î²\_2â†’r + (1-Î²\_2)â†’g^2$ &nbsp;_(biased second moment estimate)_
    - $Î±\_t â† Î± \sqrt{1 - Î²\_2^t} / (1-Î²\_1^t)$
    - $â†’Î¸ â† â†’Î¸ - \frac{Î±\_t}{\sqrt{â†’r + Îµ}}â†’s$
]

---
# Adam Bias Correction

After $t$ steps, we have $$â†’r\_t = (1 - Î²\_2) âˆ‘\_{i=1}^t Î²\_2^{t-i}â†’g\_i^2.$$

Assuming that the second moment $ğ”¼[â†’g\_i^2]$ is stationary, we have
$$\begin{aligned}
ğ”¼[â†’r\_t] &=  ğ”¼\left[(1 - Î²\_2) âˆ‘\_{i=1}^t Î²\_2^{t-i}â†’g\_i^2\right] \\\
         &=  ğ”¼[â†’g\_t^2] \cdot (1 - Î²\_2) âˆ‘\_{i=1}^t Î²\_2^{t-i} \\\
         &=  ğ”¼[â†’g\_t^2] \cdot (1 - Î²\_2^t)
\end{aligned}$$

and analogously for correction of $â†’s$.

---
# Adaptive Optimizers Animations

![:image 68%,center](optimizers-1.gif)

---
# Adaptive Optimizers Animations

![:image 85%,center](optimizers-2.gif)

---
# Adaptive Optimizers Animations

![:image 85%,center](optimizers-3.gif)

---
# Adaptive Optimizers Animations

![:image 85%,center](optimizers-4.gif)
