### Lecture: 11. Transformer, BERT
#### Date: Apr 25
#### Slides: https://ufal.mff.cuni.cz/~straka/courses/npfl114/2122/slides/?11
#### Reading: https://ufal.mff.cuni.cz/~straka/courses/npfl114/2122/slides.pdf/npfl114-11.pdf,PDF Slides
#### Questions: #lecture_11_questions

- Transformer architecture [[Attention Is All You Need](https://arxiv.org/abs/1706.03762)]
- BERT [[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)]
- RoBERTa [[RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)]
