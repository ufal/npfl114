### Lecture: 2. Training Neural Networks
#### Date: Feb 20
#### Slides: https://ufal.mff.cuni.cz/~straka/courses/npfl114/2223/slides/?02
#### Reading: https://ufal.mff.cuni.cz/~straka/courses/npfl114/2223/slides.pdf/npfl114-2223-02.pdf, PDF Slides
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl114/2223/npfl114-2223-02-czech.mp4, CZ Lecture
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl114/2223/npfl114-2223-02-english.mp4, EN Lecture
#### Questions: #lecture_2_questions
#### Lecture assignment: sgd_backpropagation
#### Lecture assignment: sgd_manual
#### Lecture assignment: mnist_training
#### Lecture assignment: gym_cartpole

- Capacity, overfitting, underfitting, regularization [Section 5.2 of DLB]
- Hyperparameters and validation sets [Section 5.3 of DLB]
- Maximum Likelihood Estimation [Section 5.5 of DLB]
- Neural network training
  - Gradient Descent and Stochastic Gradient Descent [Sections 4.3 and 5.9 of DLB]
  - Backpropagation algorithm [Section 6.5 to 6.5.3 of DLB, especially Algorithms 6.1 and 6.2; _note that Algorithms 6.5 and 6.6 are used in practice_]
  - SGD algorithm [Section 8.3.1 and Algorithm 8.1 of DLB]
  - SGD with Momentum algorithm [Section 8.3.2 and Algorithm 8.2 of DLB]
  - SGD with Nestorov Momentum algorithm [Section 8.3.3 and Algorithm 8.3 of DLB]
  - Optimization algorithms with adaptive gradients
    - AdaGrad algorithm [Section 8.5.1 and Algorithm 8.4 of DLB]
    - RMSProp algorithm [Section 8.5.2 and Algorithm 8.5 of DLB]
    - Adam algorithm [Section 8.5.3 and Algorithm 8.7 of DLB]
