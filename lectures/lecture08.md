### Lecture: 8. Word Embeddings, CRF, CTC
#### Date: Apr 20
#### Slides: https://ufal.mff.cuni.cz/~straka/courses/npfl114/1920/slides/?08
#### Reading: https://ufal.mff.cuni.cz/~straka/courses/npfl114/1920/slides.pdf/npfl114-08.pdf,PDF Slides
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl114/1920/npfl114-08.mp4,Video
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl114/1920/npfl114-08.practicals.mp4,Video â€“ Practicals
#### Video: https://slideslive.com/38907189/deep-learning-lecture-8-recurrent-neural-networks-ii-word-embeddings, 2018 Video I
#### Video: https://slideslive.com/38907422/deep-learning-lecture-9-recurrent-neural-networks-iii-machine-translation, 2018 Video II
#### Questions: #lecture_8_questions
#### Lecture assignment: mnist_multiple
#### Lecture assignment: tagger_cle_rnn
#### Lecture assignment: tagger_cle_cnn
#### Lecture assignment: tagger_competition
#### Lecture assignment: speech_recognition
#### VideoPlayer: npfl114-08.mp4,npfl114-08.practicals.mp4

- Character-level embeddings using Recurrent neural networks [C2W model from [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](http://arxiv.org/abs/1508.02096)]
- Character-level embeddings using Convolutional neural networks [CharCNN from [Character-Aware Neural Language Models](https://arxiv.org/abs/1508.06615)]
- Conditional Random Fields (CRF) loss [Sections 3.4.2 and A.7 of [Natural Language Processing (Almost) from Scratch](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf)]
- Connectionist Temporal Classification (CTC) loss [[Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks](https://www.cs.toronto.edu/~graves/icml_2006.pdf)]
